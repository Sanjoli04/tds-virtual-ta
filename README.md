# ğŸ§  TDS Virtual TA Assistant

A smart **TA (Teaching Assistant) helper** built using FastAPI that accepts **questions** and optionally an **image**, and returns an intelligent response using context-aware embeddings. Powered by **AIProxy** and OpenAI models like `gpt-4o-mini`.

---

## âœ¨ Features

- ğŸ” Accepts user **questions** via JSON or HTML form
- ğŸ–¼ï¸ Supports **image input** (base64 encoded)
- ğŸ§¾ Uses **OCR** (Tesseract) to extract text from images
- ğŸ§  Generates **embeddings** using `text-embedding-3-small`
- ğŸ”— Ranks related **document chunks** using cosine similarity
- ğŸ¤– Generates smart, context-based answers using `gpt-4o-mini`
- ğŸŒ CORS-enabled for easy frontend access

---

## ğŸ› ï¸ Tech Stack

- **FastAPI** (Python)
- **OpenAI-compatible API** via [AIProxy](https://github.com/sanand0/aipipe)
- **Tesseract OCR** for image text extraction
- **SQLite** for embedding chunk storage
- **scikit-learn** for similarity ranking

---

## ğŸš€ How It Works

1. User sends a **question** and optionally an **image**.
2. If image is provided:
   - Text is extracted via OCR.
   - This text is appended to the question for context.
3. The combined input is converted into an **embedding**.
4. Embedding is matched against local `chunks.db` for top relevant content.
5. Final answer is generated using `gpt-4o-mini` with the top chunks as context.

---

## ğŸ“¦ API Endpoints

### `POST /api`

Send a **question** with optional base64-encoded **image**.

#### ğŸ§¾ JSON Request Format
```json
{
  "question": "What does this diagram explain?",
  "image": "<optional base64-encoded image string>"
}
```